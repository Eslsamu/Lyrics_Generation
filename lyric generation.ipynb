{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lyric generation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "nlp"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jL7ABuLx7CP",
        "colab_type": "code",
        "outputId": "3e7b0f95-6567-4a9c-b7d0-83c49af63b8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!git clone https://github.com/davordavidovic/NLP-lyrics-generator.git\n",
        "  \n",
        "!sudo pip install h5py\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "fatal: destination path 'NLP-lyrics-generator' already exists and is not an empty directory.\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.16.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WyZHGl9x7Cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_songs(genre, max_tokens):\n",
        "  df1 = pd.read_csv('./NLP-lyrics-generator/data/lyrics_part1.csv')\n",
        "  df2 = pd.read_csv('./NLP-lyrics-generator/data/lyrics_part2.csv')\n",
        "  df3 = pd.read_csv('./NLP-lyrics-generator/data/lyrics_part3.csv')\n",
        "  df4 = pd.read_csv('./NLP-lyrics-generator/data/lyrics_part4.csv')\n",
        "\n",
        "  df_part_1 = pd.concat([df1, df2])\n",
        "  df_part_2 = pd.concat([df3, df4])\n",
        "\n",
        "  df = pd.concat([df_part_1, df_part_2])\n",
        "  df.drop(columns=['index','Unnamed: 0'], inplace=True) #we dont need these columns\n",
        "\n",
        "  df = df.dropna() #there were around 10000 rows with no lyrics so drop them\n",
        "  \n",
        "  df_songs = df[df.genre==genre]\n",
        "  \n",
        "  df_songs['preprocessed'] = df_songs['lyrics'].map(prepare_text)\n",
        "  \n",
        "  songs = df_songs.preprocessed.values\n",
        "  \n",
        "  count = 0\n",
        "  cut = 0\n",
        "  for i,song in enumerate(songs):\n",
        "      tokens = song.split()\n",
        "      count += len(tokens) \n",
        "      if count >= max_tokens:\n",
        "        cut = i - 1\n",
        "        break\n",
        "  print(\"Cut:\", cut, \"maxtokens\", max_tokens)      \n",
        "  print(\"Songs:\", len(songs[:cut]))\n",
        "  return songs[:cut]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjfON4R5x7DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.replace('\\n', ' newline ')\n",
        "  \n",
        "    text = text.split()\n",
        "  \n",
        "    for index, word in enumerate(text):\n",
        "        #remove non alphabetic characters at the end or beginning of a word\n",
        "        word = word.strip(string.punctuation)\n",
        "    \n",
        "        #replace non alhpanumeric chars with space\n",
        "        word = re.sub(r\"[\\W]\",' ',word)\n",
        "        text[index] = word \n",
        "   \n",
        "    #concatenate again\n",
        "    text = \" \".join(text)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqEpW5kjx7DM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import OrderedDict\n",
        "\n",
        "def build_vocab(songs, min_frq):\n",
        "  #token pattern to also count one-character words\n",
        "  vectorizer = CountVectorizer(stop_words=[],min_df=min_frq,token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\")\n",
        "  X = vectorizer.fit_transform(songs)\n",
        "\n",
        "\n",
        "  vocab_dict = vectorizer.vocabulary_\n",
        "  vocab_list =  list(vocab_dict)\n",
        "\n",
        "  return vocab_list, vocab_dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNrFi8o-x7DU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def index2sen(seq,vocab):\n",
        "    tokens = [vocab[int(t)] for t in seq]\n",
        "    sen = \" \".join(tokens)\n",
        "    return sen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciHlKPITx7DY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "\n",
        "def songs_to_supervised(seq_len, songs, vocab_dict, vocab_list):\n",
        "  data_x = []\n",
        "  data_y = []\n",
        "  seq_words = []\n",
        "  miss_count = 0\n",
        "  for song in songs:\n",
        "      tokens = song.split()\n",
        "      for i in range(0, len(tokens) - seq_len):\n",
        "          seq_in = tokens[i:i+seq_len]\n",
        "          seq_out = tokens[i + seq_len]\n",
        "          seq_data = []\n",
        "          \n",
        "          for word in seq_in:\n",
        "              if word in vocab_dict:\n",
        "                  seq_data.append(vocab_list.index(word))\n",
        "              else:\n",
        "                  break\n",
        "                  \n",
        "          #check if all words in sequence are in dict\n",
        "          if len(seq_data) == seq_len and seq_out in vocab_dict:\n",
        "              data_x.append(seq_data)\n",
        "              data_y.append(vocab_list.index(seq_out))\n",
        "              seq_words.append((seq_in,seq_out))\n",
        "          else:\n",
        "            miss_count += 1\n",
        "          '''\n",
        "          #return if enough sequences were created\n",
        "          if len(data_x) == n_seq:\n",
        "            return data_x, data_y \n",
        "          '''\n",
        "  print(\"missed sequences\", miss_count)\n",
        "  return data_x, data_y, seq_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTgH2EI8vISd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_embedding_model(layers, units, n_vocab, seq_len):\n",
        "  #lstm sequence to categoriemodel\n",
        "  model = Sequential()\n",
        "  \n",
        "  #word embedding layer\n",
        "  model.add(Embedding(input_dim=n_vocab, output_dim = 32, input_length = seq_len))\n",
        "  \n",
        "  for l in range(layers-1):\n",
        "    model.add(CuDNNLSTM(units,return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "  \n",
        "  model.add(CuDNNLSTM(units,return_sequences=False))\n",
        "  model.add(Dropout(0.2)) \n",
        "  \n",
        "  model.add(Dense(n_vocab, activation='softmax'))\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "  \n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RKNDDN9xv8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdUrn2U7x7D2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense,Dropout, CuDNNLSTM, Flatten\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku \n",
        "\n",
        "def create_model(layers, units, inp_shape, out_shape):\n",
        "  #lstm sequence to categoriemodel\n",
        "  model = Sequential()\n",
        "  \n",
        "  for l in range(layers-1):\n",
        "    model.add(CuDNNLSTM(units,return_sequences=True, input_shape = inp_shape))\n",
        "    \n",
        "  model.add(CuDNNLSTM(units,return_sequences=False))\n",
        "  model.add(Dropout(0.2)) \n",
        "  model.add(Dense(out_shape, activation='softmax'))\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['sparse_categorical_accuracy'])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHj1jiBY2GzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(seed_text, next_words, model, vocab_list):\n",
        "    n_vocab = len(vocab_list)\n",
        "    seq_in = prepare_text(seed_text).split()\n",
        "    x = np.array([vocab_list.index(word) for word in seq_in])\n",
        "    #normalize\n",
        "    x = x/n_vocab\n",
        "    \n",
        "    output_word = \"\"\n",
        "    predictions = []\n",
        "    for i in range(next_words):\n",
        "        input_seq = np.reshape(np.append(x[i:],predictions),(1,len(x),1))\n",
        "        predicted = model.predict_classes(input_seq, verbose=0)\n",
        "        predictions.append(predicted[0])\n",
        "        output_word = vocab_list[predicted[0]]\n",
        "        seed_text += \" \" + output_word\n",
        "        #print(output_word, vocab_list[np.argmax(model.predict(input_seq,verbose=0))])\n",
        "        \n",
        "    return seed_text\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ial_8bsflgmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "import numpy as np \n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        " \n",
        "  \n",
        "def run_experiment(n_sequences, n_epochs, genre, seq_len, n_layers, max_vocab_size, directory):\n",
        "\n",
        "  print(\"Running\", n_sequences,\"sequences\", n_epochs,\"epochs\",genre, seq_len,\"sequence length\", n_layers, \"layers\", max_vocab_size, \"vocab size\", directory, \"directory\") \n",
        "  \n",
        "  #load lyrics with this many tokens\n",
        "  max_tokens = n_sequences-seq_len\n",
        "  \n",
        "  #load song lyrics\n",
        "  songs = load_songs(genre, max_tokens)\n",
        "  \n",
        "  #create the right-sized vocabulary from the songs \n",
        "  min_frq = 1\n",
        "  n_vocab = np.inf\n",
        "  while n_vocab > max_vocab_size:\n",
        "    vocab_list, vocab_dict = build_vocab(songs, min_frq)\n",
        "    n_vocab = len(vocab_dict)\n",
        "    min_frq += 1\n",
        "  print(\"vocab len:\", n_vocab)\n",
        "  \n",
        "  #songs to sequences and labels\n",
        "  data_x, data_y, seq_words = songs_to_supervised(seq_len, songs, vocab_dict, vocab_list)\n",
        "  \n",
        "  print(\"data x len\",len(data_x))\n",
        "  \n",
        "  #reshape input to samples, timesteps, features\n",
        "  X = np.reshape(data_x, (len(data_x), seq_len, 1))\n",
        "  #normalize input\n",
        "  X = X/float(n_vocab)\n",
        "  #categorical labels \n",
        "  #y = np_utils.to_categorical(data_y)\n",
        "  y = np.array(data_y)\n",
        "  \n",
        "  inp_shape = X[0].shape\n",
        "  out_shape = y.shape[0]\n",
        "  \n",
        "  #create the lstm model\n",
        "  model = create_model(n_layers, units=400, inp_shape =inp_shape, out_shape=out_shape)\n",
        "  #model = create_embedding_model(n_layers, 200,n_vocab, seq_len)\n",
        "  \n",
        "  \n",
        "  # checkpoint\n",
        "  #TODO adapt filepath\n",
        "  filepath = directory + \"weights-improvement-{epoch:02d}-{acc:.2f}.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "  #early stopping \n",
        "  es = EarlyStopping(monitor='val_acc', mode='min', verbose=1, patience=100)\n",
        "\n",
        "  callbacks_list = [es]\n",
        "  \n",
        "  #train model\n",
        "  history = model.fit(X, y, epochs=n_epochs, verbose=1,batch_size=512,callbacks=callbacks_list, validation_split=0.1)\n",
        "  \n",
        "  #save model TODO namin\n",
        "  model.save(directory +\"model.h5\")\n",
        "  \n",
        "  #save history\n",
        "  with open(directory+\"hist\", 'wb') as file_pi:\n",
        "        pickle.dump(history.history, file_pi)\n",
        "  \n",
        "  #generate validation texts and training texts\n",
        "  val_words = seq_words[:-10]\n",
        "  for t in val_words:\n",
        "    sentence = \" \".join(t[0])\n",
        "    label = t[1]\n",
        "    output = generate_text(sentence, next_words = seq_len, model = model, vocab_list = vocab_list)\n",
        "    with open(directory + \"generated.txt\",\"w\") as file:\n",
        "      file.write(sentence + \" out: \" + output + \"\\n\")\n",
        "      #also save the actual number of sequences that were used\n",
        "      file.write(str(len(data_x)))\n",
        "  \n",
        "  \n",
        "  #TODO save plot on training curve\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['training', 'test'], loc='upper left')\n",
        "  plot_path = directory + \"plot.png\"\n",
        "  plt.savefig(plot_path, bbox_inches='tight', format='png')\n",
        "  print(\"Finished experiment\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyo8D4y_maAS",
        "colab_type": "code",
        "outputId": "db814c0e-831c-46b2-c8f7-506e17d5f923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7960
        }
      },
      "source": [
        "data_sizes = [50000, 100000, 250000] #num of sequences\n",
        "epochs = [50,200]\n",
        "genres = ['Metal', 'Country','Pop','Hip-Hop']\n",
        "seq_lens = [5,10,20]\n",
        "layers = [4, 6] #400 units each\n",
        "max_vocab_size = [600, 1000] #change min document frq until size fits\n",
        "\n",
        "experiments = []\n",
        "\n",
        "#big dataset on all genres with different vocabulary sizes\n",
        "for g in genres:\n",
        "  for m in max_vocab_size:\n",
        "    exp = {\"seqs\" : data_sizes[0],\n",
        "           \"epochs\" : epochs[1],\n",
        "           \"genre\" : g,\n",
        "           \"seq_lens\" : seq_lens[1],\n",
        "           \"layers\" : layers[0],\n",
        "           \"vocab\" : m,\n",
        "           \"dir\" : \"./gdrive/My Drive/Colab Notebooks/exps2/_\" + str(m) + g\n",
        "          }\n",
        "    experiments.append(exp)\n",
        "\n",
        "#different data sizes on hip hop\n",
        "for d in data_sizes:\n",
        "  exp = {\"seqs\" : d,\n",
        "         \"epochs\" : epochs[1],\n",
        "         \"genre\" : genres[1],\n",
        "         \"seq_lens\" : seq_lens[1],\n",
        "         \"layers\" : layers[1],\n",
        "         \"vocab\" : max_vocab_size[1],\n",
        "         \"dir\" : \"./gdrive/My Drive/Colab Notebooks/exps2/_\" + str(d) + \"sequences\"\n",
        "          }\n",
        "  experiments.append(exp)\n",
        "\n",
        "#different sequence lengths on hip hop\n",
        "for s in seq_lens:\n",
        "  exp = {\"seqs\" : data_sizes[2],\n",
        "         \"epochs\" : epochs[1],\n",
        "         \"genre\" : genres[1],\n",
        "         \"seq_lens\" : seq_lens[1],\n",
        "         \"layers\" : layers[1],\n",
        "         \"vocab\" : max_vocab_size[1],\n",
        "         \"dir\" : \"./gdrive/My Drive/Colab Notebooks/exps2/_\" + str(d) + \"sequences\"\n",
        "          }\n",
        "  experiments.append(exp)\n",
        "  \n",
        "        \n",
        "print(\"Running\", len(experiments), \"experiments\")\n",
        "            \n",
        "for e in experiments:\n",
        "  #try:\n",
        "    n_seqs = e[\"seqs\"]\n",
        "    n_epochs = e[\"epochs\"]\n",
        "    genre = e[\"genre\"]\n",
        "    seq_len = e[\"seq_lens\"]\n",
        "    n_layers = e[\"layers\"]\n",
        "    max_vocab_size = e[\"vocab\"]\n",
        "    dir_ = e[\"dir\"]\n",
        "    run_experiment(n_sequences = n_seqs, n_epochs = n_epochs, genre = genre, seq_len = seq_len, n_layers = n_layers, max_vocab_size = max_vocab_size, directory = dir_)\n",
        "  #except Exception as ex:\n",
        "   # print(\"Exception\",ex)\n",
        "    #pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running 14 experiments\n",
            "Running 50000 sequences 200 epochs Metal 10 sequence length 4 layers 600 vocab size ./gdrive/My Drive/Colab Notebooks/exps2/_600Metal directory\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cut: 263 maxtokens 49990\n",
            "Songs: 263\n",
            "vocab len: 566\n",
            "missed sequences 37325\n",
            "data x len 9665\n",
            "Train on 8698 samples, validate on 967 samples\n",
            "Epoch 1/200\n",
            "8698/8698 [==============================] - 11s 1ms/step - loss: 7.0589 - sparse_categorical_accuracy: 0.1326 - val_loss: 5.3376 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 2/200\n",
            " 512/8698 [>.............................] - ETA: 1s - loss: 4.9964 - sparse_categorical_accuracy: 0.1426"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_sparse_categorical_accuracy,loss,sparse_categorical_accuracy\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8698/8698 [==============================] - 2s 248us/step - loss: 5.0146 - sparse_categorical_accuracy: 0.1404 - val_loss: 5.3388 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 3/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9506 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2355 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 4/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9281 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2418 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 5/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9194 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2281 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 6/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9297 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2290 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 7/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9294 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2212 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 8/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9233 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2301 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 9/200\n",
            "8698/8698 [==============================] - 2s 251us/step - loss: 4.9278 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2334 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 10/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9245 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2259 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 11/200\n",
            "8698/8698 [==============================] - 2s 251us/step - loss: 4.9225 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2277 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 12/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9226 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2195 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 13/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9262 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2182 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 14/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9277 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2302 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 15/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9266 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2219 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 16/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9274 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2415 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 17/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9306 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2345 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 18/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9282 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2267 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 19/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9280 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2302 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 20/200\n",
            "8698/8698 [==============================] - 2s 251us/step - loss: 4.9215 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2133 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 21/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9289 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2389 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 22/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9267 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2121 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 23/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9253 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2407 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 24/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9243 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2230 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 25/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9228 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2329 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 26/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9227 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2265 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 27/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9226 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2271 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 28/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9198 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2326 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 29/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9224 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2373 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 30/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9312 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2231 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 31/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9253 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2255 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 32/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9245 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2135 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 33/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9242 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2490 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 34/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9205 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2185 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 35/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9238 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2363 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 36/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9209 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2397 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 37/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9273 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2338 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 38/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9299 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2431 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 39/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9282 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2173 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 40/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9299 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2275 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 41/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9212 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2163 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 42/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9275 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2234 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 43/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9259 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2146 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 44/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9272 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2381 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 45/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9223 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2124 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 46/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9217 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2208 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 47/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9215 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2145 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 48/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9237 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2354 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 49/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9284 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2071 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 50/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9279 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2297 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 51/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9284 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2433 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 52/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9254 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2255 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 53/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9271 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2362 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 54/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9249 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2410 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 55/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9219 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2358 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 56/200\n",
            "8698/8698 [==============================] - 2s 251us/step - loss: 4.9265 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2347 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 57/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9209 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2391 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 58/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9288 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2149 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 59/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9223 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2183 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 60/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9277 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2214 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 61/200\n",
            "8698/8698 [==============================] - 2s 242us/step - loss: 4.9292 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2307 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 62/200\n",
            "8698/8698 [==============================] - 2s 243us/step - loss: 4.9298 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2029 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 63/200\n",
            "8698/8698 [==============================] - 2s 244us/step - loss: 4.9252 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2376 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 64/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9258 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2127 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 65/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9193 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2229 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 66/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9242 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2281 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 67/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9228 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2329 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 68/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9256 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2380 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 69/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9235 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2279 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 70/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9218 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2288 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 71/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9222 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2302 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 72/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9255 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2256 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 73/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9189 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2171 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 74/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9221 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2141 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 75/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9245 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2344 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 76/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9202 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2373 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 77/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9251 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2184 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 78/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9224 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2324 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 79/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9208 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2308 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 80/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9332 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2315 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 81/200\n",
            "8698/8698 [==============================] - 2s 250us/step - loss: 4.9276 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2169 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 82/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9229 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2308 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 83/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9277 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2308 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 84/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9287 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2447 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 85/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9285 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2352 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 86/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9207 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2148 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 87/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9211 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2279 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 88/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9225 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2327 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 89/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9235 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2256 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 90/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9245 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2231 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 91/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9239 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2183 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 92/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9287 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2253 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 93/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9227 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2276 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 94/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9258 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2257 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 95/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9258 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2280 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 96/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9196 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2270 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 97/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9231 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2133 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 98/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9257 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2297 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 99/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9263 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2210 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 100/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9247 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2010 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 101/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9245 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2290 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 102/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9222 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2314 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 103/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9236 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2314 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 104/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9223 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2179 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 105/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9267 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2070 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 106/200\n",
            "8698/8698 [==============================] - 2s 250us/step - loss: 4.9201 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2345 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 107/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9207 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2160 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 108/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9163 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2126 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 109/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9154 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2348 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 110/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9241 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2204 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 111/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9207 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2347 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 112/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9195 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2141 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 113/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9189 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2127 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 114/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9254 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2168 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 115/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9209 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2220 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 116/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9168 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2098 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 117/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9228 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2028 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 118/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9199 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2217 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 119/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9199 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2159 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 120/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9174 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2274 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 121/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9204 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2259 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 122/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9145 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2391 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 123/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9191 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2238 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 124/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9195 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2232 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 125/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9125 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2100 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 126/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9185 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2230 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 127/200\n",
            "8698/8698 [==============================] - 2s 250us/step - loss: 4.9185 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2246 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 128/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9115 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2164 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 129/200\n",
            "8698/8698 [==============================] - 2s 250us/step - loss: 4.9115 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2169 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 130/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9102 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2251 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 131/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9146 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.1998 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 132/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9143 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2156 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 133/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9139 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2244 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 134/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9111 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2201 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 135/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9112 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2256 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 136/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9105 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2099 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 137/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9109 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2120 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 138/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.9116 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2053 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 139/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9089 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2247 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 140/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9073 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2083 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 141/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.9094 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2086 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 142/200\n",
            "8698/8698 [==============================] - 2s 250us/step - loss: 4.9070 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2214 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 143/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.9041 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2039 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 144/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9039 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2162 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 145/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.9002 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2105 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 146/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9008 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2136 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 147/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.9017 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2009 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 148/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.8998 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2053 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 149/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8990 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2089 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 150/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8987 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2057 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 151/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.8963 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2040 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 152/200\n",
            "8698/8698 [==============================] - 2s 250us/step - loss: 4.8919 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.1997 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 153/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8970 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2228 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 154/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.8902 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2148 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 155/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.8953 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2014 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 156/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8938 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2204 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 157/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.8936 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2086 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 158/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.8916 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2010 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 159/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.8911 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2113 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 160/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.8927 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2118 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 161/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.8951 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2135 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 162/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.8920 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2054 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 163/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8896 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2094 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 164/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8895 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2085 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 165/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.8901 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.1997 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 166/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.8868 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2262 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 167/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.8896 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2052 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 168/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8880 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2136 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 169/200\n",
            "8698/8698 [==============================] - 2s 250us/step - loss: 4.8868 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2075 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 170/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8878 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2020 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 171/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.8877 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2089 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 172/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.8867 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2025 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 173/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.8913 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2055 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 174/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.8878 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2163 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 175/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.8858 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.1997 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 176/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.8858 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2047 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 177/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8867 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2085 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 178/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.8864 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2014 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 179/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8846 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2104 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 180/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8852 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2037 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 181/200\n",
            "8698/8698 [==============================] - 2s 243us/step - loss: 4.8857 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2055 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 182/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8854 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2122 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 183/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8849 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2097 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 184/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.8861 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2094 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 185/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.8851 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2050 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 186/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8839 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2097 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 187/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8844 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2084 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 188/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.8859 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2076 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 189/200\n",
            "8698/8698 [==============================] - 2s 250us/step - loss: 4.8884 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2070 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 190/200\n",
            "8698/8698 [==============================] - 2s 246us/step - loss: 4.8831 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2112 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 191/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8863 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2090 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 192/200\n",
            "8698/8698 [==============================] - 2s 250us/step - loss: 4.8866 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2080 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 193/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8856 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2106 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 194/200\n",
            "8698/8698 [==============================] - 2s 247us/step - loss: 4.8859 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2092 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 195/200\n",
            "8698/8698 [==============================] - 2s 251us/step - loss: 4.8859 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2048 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 196/200\n",
            "8698/8698 [==============================] - 2s 250us/step - loss: 4.8849 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2058 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 197/200\n",
            "8698/8698 [==============================] - 2s 248us/step - loss: 4.8852 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2100 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 198/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.8840 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2033 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 199/200\n",
            "8698/8698 [==============================] - 2s 249us/step - loss: 4.8844 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2039 - val_sparse_categorical_accuracy: 0.1303\n",
            "Epoch 200/200\n",
            "8698/8698 [==============================] - 2s 245us/step - loss: 4.8850 - sparse_categorical_accuracy: 0.1414 - val_loss: 5.2073 - val_sparse_categorical_accuracy: 0.1303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-98182a5df9a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mmax_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mdir_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdir_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;31m#except Exception as ex:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m    \u001b[0;31m# print(\"Exception\",ex)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-c438a9e568eb>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(n_sequences, n_epochs, genre, seq_len, n_layers, max_vocab_size, directory)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"generated.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" out: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-1c5c8998eb62>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(seed_text, next_words, model, vocab_list)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutput_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9OdkEz8Zn2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7ccRpjBUlM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uoh-hxHK2K2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load from last checkpoint\n",
        "model.load_weights('content/gdrive/My Drive/Colab Notebooks/weights-improvement-77-0.41.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88Qw98N_1Ux3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train and save model\n",
        "history=model.fit(X, y, epochs=200, verbose=1,batch_size=1024,callbacks=callbacks_list, validation_split=0.1)\n",
        "model.save(\"./gdrive/My Drive/Colab Notebooks/200ep_4_lay_model_10000_pop_15seq.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEaxt9qZx7EK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(generate_text(\"Oh baby, baby, how was I supposed to know That something wasn't right here\",10,model))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmM2QHV_bYph",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdjcTFwxt25-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('./gdrive/My Drive/Colab Notebooks/bigmodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57CzlAFXx7Ek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS6SGZDXuZQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#------------------CLASSIFICATION -----------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0AxzyO8FGzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}